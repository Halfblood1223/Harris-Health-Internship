{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76641810-57b8-4598-bd3c-9ca7be9ec5a1",
   "metadata": {},
   "source": [
    "# Covid-19 Visualization\n",
    "\n",
    "## Tools\n",
    "- Holoviews\n",
    "- Folium\n",
    "\n",
    "## Visualizations\n",
    "- ScatterPlot with Slider\n",
    "- Dot Map of all data points\n",
    "- Size Map based on Cases\n",
    "- Size Map based on Deaths\n",
    "- Heat Map based on Deaths\n",
    "- Heat Map based on Cases\n",
    "- Heat Map based on Deaths Per Cases\n",
    "- Heat Map based on Deaths | Time Slider Enabled\n",
    "- Heat Map based on Cases | Time Slider Enabled\n",
    "- Heat Map based on Deaths Per Cases | Time Slider Enabled\n",
    "\n",
    "[Kaggle Dataset](https://www.kaggle.com/fireballbyedimyrnmom/us-counties-covid-19-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577326fd-e509-433e-8c52-1203c1b0a297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopy\n",
    "import folium\n",
    "\n",
    "import datetime as dt\n",
    "import math\n",
    "\n",
    "hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84cd8da-525a-40ea-97b5-0dac525f4a07",
   "metadata": {},
   "source": [
    "## Load Dataset as Pandas Dataframe\n",
    "Data is 1.5 million lines long. Includes 3247 distinct counties and runs for 552 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29351e70-37f6-44bd-b38b-45826b755a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/us-counties.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c936ea5-7266-472d-917e-719d84fd5b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bfbdfd-ac7f-4100-baa8-e0db5e88b991",
   "metadata": {},
   "source": [
    "## Adding Deaths per Cases Metric\n",
    "\n",
    "This will be useful at the end when we make a time slider enabled heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f4e30d-9f96-4636-a0f6-7b54ce98c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DPC'] = df['deaths'] / df['cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7bb9b-8e89-4995-b0f0-2387fee3015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0) # fill nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a605b-1d55-4883-ad72-55a51e7d0628",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb79499-0e4a-4e5b-b88b-0fc10fae3b49",
   "metadata": {},
   "source": [
    "## Seperate into days and then Counties\n",
    "\n",
    "**Expected End Result**\n",
    "<br>\n",
    "Date -> County -> Cases | Deaths | Fips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70496576-4546-465b-85c5-ab3baadeeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def county_date_seperated(df):\n",
    "    cdsd = df.groupby(['date', 'county', 'state']).sum()\n",
    "    return cdsd\n",
    "\n",
    "cdsd = county_date_seperated(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc680274-192c-4708-aeeb-e3aef62b246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdsd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d00af4-0cd1-4a27-ae74-4bdc7f8768c6",
   "metadata": {},
   "source": [
    "## ScatterPlot with Slider\n",
    "\n",
    "- Plots the amount of deaths for each county at a given date\n",
    "- Date is selected with the slider\n",
    "- Slider selects a day that is {slider value} days away from the origin\n",
    "\n",
    "**Names aren't clear because of the large amount of counties.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5528b7-e33c-4532-b02c-d6d8879e716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dgraph(td):\n",
    "    origin = dt.date(2020, 1, 21) # data startpoint\n",
    "    req_date = origin + dt.timedelta(days=td) # day td days after the origin\n",
    "    req_data = cdsd['deaths'][str(req_date).split(' ')[0]] # returns df for the given day\n",
    "    data = [(f\"{county[0]}, {county[1]}\", entry) for county, entry in req_data.iteritems()] # creates list of tuple pairs (county name, deaths)\n",
    "    return hv.Scatter(data, hv.Dimension('Counties'), 'Deaths') # pass scatter plot to holoviews dynamicmap\n",
    "\n",
    "dmap = hv.DynamicMap(dgraph, kdims=['Days_From_Origin'])\n",
    "dmap.redim.range(Days_From_Origin=(0,552))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4768f91-e5f1-431d-b93d-bcf57dbc983d",
   "metadata": {},
   "source": [
    "## Geocoding Each County\n",
    "\n",
    "This script takes the names of each county and then returns a set of coordinates back. This is rate limited and will take a very long time. It is advised to run this once and then download the coordinate dataframe as a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3667e-1b63-4f59-b5f3-e3163ce66413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# geocode the counties\n",
    "\n",
    "from geopy.geocoders import Nominatim # open source geocoder\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import tqdm # progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "def geocode(df):\n",
    "    geolocator = Nominatim(user_agent=\"Covid-19 Visualization\")\n",
    "    geocode = RateLimiter(geolocator.geocode, min_delay_seconds=1) # rate limiter\n",
    "    county_list = df[['county', 'state']].groupby(['county', 'state']).count().index # gets county values by grouping by county and state\n",
    "    coords_df = {} # instantiates our final coordinates dictionary\n",
    "    error_counties = [] # tracks any errors that occur\n",
    "    for county in tqdm(county_list): # iterate through county list\n",
    "        address = f\"{county[0]}, {county[1]}\" # county one line address\n",
    "        location = geolocator.geocode(f\"{address}, USA\") # geocoder\n",
    "        try: # error handling if the geocoder doesn't find a suitable address\n",
    "            coords_df[address] = (location.latitude, location.longitude)\n",
    "        except:\n",
    "            error_counties.append(address)\n",
    "    return coords_df, error_counties\n",
    "\n",
    "coords_df, error_counties = geocode(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e888eafc-efb0-4e56-9e7e-ec7723664137",
   "metadata": {},
   "source": [
    "### Saves Coords_DF as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f0fba-a779-4e59-a812-475d2afcb160",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df = pd.DataFrame.from_dict(coords_df)\n",
    "coords_df.to_csv('../datasets/coords-us-counties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c54a23-e1ae-4899-9bd7-21181c59f991",
   "metadata": {},
   "source": [
    "### Pulls Coords_DF from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ef492b-a5dc-4410-a119-fa50029f12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_df = pd.read_csv('../datasets/coords-us-counties.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3659b397-f6c5-4999-b8ef-605a9b67fd7e",
   "metadata": {},
   "source": [
    "## Dot Map of all data points\n",
    "\n",
    "Plots a point at the geocoded coordinate for each county in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711bc98-7576-4b0c-a470-26a9d914ac1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dp_map = folium.Map(location=[39.5, -98.35]) # create map at the centermost points of the us\n",
    "\n",
    "for coords in coords_df: # iterate through all the coordinates in the coordinate dataframe\n",
    "    x, y = coords_df[coords][0], coords_df[coords][1]\n",
    "    folium.CircleMarker(\n",
    "        location=[x, y],\n",
    "        popup=coords,\n",
    "        radius=5\n",
    "    ).add_to(dp_map) # adds dot to folium map\n",
    "    \n",
    "dp_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec204707-c877-40c0-a58b-2d0fd8f94d93",
   "metadata": {},
   "source": [
    "## Size Map Function\n",
    "\n",
    "Draws from CDSD which is grouped by Date, County, and State in that order.\n",
    "\n",
    "Can be used with any metric and any day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f68f187-1992-4377-b2b0-0347f1620af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def s_map(td: int, metric: str, folium_map: folium.Map, scaler=1): \n",
    "    # s_map is designed to be metric agnostic\n",
    "    error_counties = [] # list to hold all counties we get errors on\n",
    "    origin = dt.date(2020, 1, 21) # starting point of our data\n",
    "    req_date = origin + dt.timedelta(days=td) # returns the requested date of this formula. original date + days_elapsed\n",
    "    req_data = cdsd[metric][str(req_date).split(' ')[0]]\n",
    "    normalizer = req_data.sum() # gets sum of all deaths in a day. used for normalization later\n",
    "    for row in req_data.iteritems():\n",
    "        location = row[0]\n",
    "        address = f\"{location[0]}, {location[1]}\" # one line address\n",
    "        metric_count = row[1]\n",
    "        try:\n",
    "            x, y = coords_df[address][0], coords_df[address][1] # look up coordinates in our coords dataframe\n",
    "        except:\n",
    "            error_counties.append(address) # return error if we are unable to find coords\n",
    "        folium.CircleMarker(\n",
    "            location=[x, y],\n",
    "            popup=address,\n",
    "            radius=metric_count / normalizer * scaler, # scaler is meant to down or upscale the data\n",
    "            fill=True\n",
    "        ).add_to(folium_map) # add marker to folium map\n",
    "    return error_counties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89be512-b710-42a5-9b17-b972ec2121e9",
   "metadata": {},
   "source": [
    "## Size Map by Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c58d2-3c95-4bbb-ae1e-ab507c736010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_map_cases = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "error_counties_cases = s_map(500, 'cases', s_map_cases)\n",
    "\n",
    "print(error_counties_cases)\n",
    "\n",
    "s_map_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721d29d-00b9-4f94-aff4-86b17012de4f",
   "metadata": {},
   "source": [
    "## Size Map by Deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced25477-5f52-4780-b156-ab6a47510200",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_map_deaths = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "error_counties_deaths = s_map(500, 'deaths', s_map_deaths)\n",
    "\n",
    "print(error_counties_deaths)\n",
    "\n",
    "s_map_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2c4e79-523c-4039-bc27-b56654f3cf15",
   "metadata": {},
   "source": [
    "## Date Specific Heatmap Data Creation\n",
    "\n",
    "Returns data for a specific date given a timedelta, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017ce7c-a1a1-475c-96b2-51856ecf7845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_specific_heatmap_data(td: int, metric: str, scaler=1):\n",
    "    error_counties = [] # list to hold all counties we get errors on\n",
    "    heat_data = [] # list to hold lists of each county in a day\n",
    "    origin = dt.date(2020, 1, 21) # starting point of our data\n",
    "    req_date = origin + dt.timedelta(days=td) # returns the requested date of this formula. original date + days_elapsed\n",
    "    req_data = cdsd[metric][str(req_date).split(' ')[0]]\n",
    "    normalizer = req_data.sum()\n",
    "    for row in req_data.iteritems():\n",
    "        location = row[0]\n",
    "        address = f\"{location[0]}, {location[1]}\" # one line address\n",
    "        metric_count = row[1]\n",
    "        metric_count_normalized = metric_count / normalizer * scaler\n",
    "        if math.isnan(metric_count_normalized):\n",
    "            metric_count_normalized = 0\n",
    "        try:\n",
    "            x, y = coords_df[address][0], coords_df[address][1] # look up coordinates in our coords dataframe\n",
    "        except:\n",
    "            error_counties.append(address) # return error if we are unable to find coords\n",
    "        heat_data.append([x, y, metric_count_normalized])\n",
    "    return heat_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a0412e-219d-4ddd-be25-6079c02f440a",
   "metadata": {},
   "source": [
    "## Heat Map based on Deaths\n",
    "\n",
    "Map is insightful when zoomed into a multi-state or below scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdb1b60-ccbb-4eca-b652-932f4ce9295e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMap\n",
    "\n",
    "hmap_deaths = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "heat_data_deaths_date = date_specific_heatmap_data(500, 'deaths', scaler=0.1)\n",
    "\n",
    "HeatMap(heat_data_deaths_date).add_to(hmap_deaths)\n",
    "\n",
    "hmap_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f8b6a8-3dd5-49df-bbd8-55f607d696c0",
   "metadata": {},
   "source": [
    "## Heat Map based on Cases\n",
    "\n",
    "Map is insightful when zoomed into a multi-state or below scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54544a3-dc19-4da2-b74f-6dcb29325a75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hmap_cases = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "heat_data_cases_date = date_specific_heatmap_data(500, 'cases', scaler=0.1)\n",
    "\n",
    "HeatMap(heat_data_cases_date).add_to(hmap_cases)\n",
    "\n",
    "hmap_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517549e-3f47-40f3-a8bd-47d313be7906",
   "metadata": {},
   "source": [
    "## Date Agnostic Heatmap Data Creation\n",
    "\n",
    "Creates the time series data necessary for a heatmap with slider.\n",
    "\n",
    "**Data Structure**\n",
    "`[date1: [date_specific_heatmap_data(date)], date2: [date_specific_heatmap_data(date)]...]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a48a34d-86cc-4bca-8f3c-7e7ea356a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_agnostic_heatmap_data(metric: str, scaler=1):\n",
    "    heat_data_date_agnostic = []\n",
    "    for date in range(551):\n",
    "        curr_data = date_specific_heatmap_data(date, metric)\n",
    "        heat_data_date_agnostic.append(curr_data)\n",
    "    return heat_data_date_agnostic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815cd13-1cb5-47a7-9c40-813b2e82b0ab",
   "metadata": {},
   "source": [
    "## Heat Map based on Deaths | Time Slider Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8185c766-cbc5-4cac-b306-365bffc2e981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from folium.plugins import HeatMapWithTime\n",
    "\n",
    "hmap_timeslider_deaths = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "heat_data_date_agnostic_deaths = data_agnostic_heatmap_data('deaths')\n",
    "\n",
    "HeatMapWithTime(heat_data_date_agnostic_deaths).add_to(hmap_timeslider_deaths)\n",
    "\n",
    "hmap_timeslider_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c619323-4f8b-4500-b915-2d14c47f775e",
   "metadata": {},
   "source": [
    "## Heat Map based on Cases | Time Slider Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7edefcf-2b43-4d6e-9716-22cafbe5846d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hmap_timeslider_cases = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "heat_data_date_agnostic_cases = data_agnostic_heatmap_data('cases')\n",
    "\n",
    "HeatMapWithTime(heat_data_date_agnostic_cases).add_to(hmap_timeslider_cases)\n",
    "\n",
    "hmap_timeslider_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db5cbd4-fae7-42fa-94a9-a07bc26413b5",
   "metadata": {},
   "source": [
    "## Implementing a new metric\n",
    "\n",
    "Implementing a new metric is simple. Preprocessing can be done at the beginning. From there metrics can be selected through the extensible functions I've written."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d0783-016d-41e8-9b2e-bddd6ef979fe",
   "metadata": {},
   "source": [
    "## Heatmap based on Deaths per Cases | Time Slider Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b625a40-5b11-4e84-888c-35bdf4d25284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hmap_timeslider_dpc = folium.Map(location=[39.5, -98.35])\n",
    "\n",
    "heat_data_date_agnostic_dpc = data_agnostic_heatmap_data('DPC', scaler=0.1)\n",
    "\n",
    "HeatMapWithTime(heat_data_date_agnostic_dpc).add_to(hmap_timeslider_dpc)\n",
    "\n",
    "hmap_timeslider_dpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee7ab1-872b-43ae-8f58-594192ff968b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1567e-28cc-47cd-afd1-e35df5e7e8c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e4b43-0772-454e-89db-45a7774bc46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
